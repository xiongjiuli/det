{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 造高斯函数\n",
    "import numpy as np\n",
    "import torchio as tio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "def create_gaussian_base(size, threshold):\n",
    "\n",
    "    if size <= 9:\n",
    "        _size = 9\n",
    "        half_dis = (_size + 1) / 2.\n",
    "    else:\n",
    "        _size = size\n",
    "        if _size % 2 != 1:  # 如果size是偶数就变成奇数\n",
    "            half_dis = _size / 2.\n",
    "            _size = _size + 1\n",
    "        else:\n",
    "            half_dis = (_size + 1) / 2.\n",
    "\n",
    "    if threshold == 0.5:\n",
    "        sigma = np.sqrt(half_dis**2 / (2 * np.log(2)))\n",
    "    elif threshold == 0.8:\n",
    "        sigma = np.sqrt(half_dis**2 / (2 * (np.log(5) - np.log(4))))\n",
    "    elif threshold == 0.3:\n",
    "        sigma = np.sqrt(half_dis**2 / (2 * (np.log(10) - np.log(3))))\n",
    "    else:\n",
    "        print(f'when x = distance, the y wrong input, now the threshold is {threshold}')\n",
    "\n",
    "    kernel = np.zeros((int(_size), int(_size), int(_size)))\n",
    "    center = tuple(s // 2 for s in (int(_size), int(_size), int(_size)))\n",
    "    kernel[center] = 1\n",
    "    gassian_kernel = gaussian_filter(kernel, sigma=sigma)\n",
    "\n",
    "    arr_min = gassian_kernel.min()\n",
    "    arr_max = gassian_kernel.max()\n",
    "    normalized_arr = (gassian_kernel - arr_min) / (arr_max - arr_min) # 归一化到 0-1 之间\n",
    "    # print(f'in the create_gaussian_base , the max is {normalized_arr.max()}, the min is {normalized_arr.min()}')\n",
    "    return normalized_arr\n",
    "\n",
    "\n",
    "\n",
    "def create_gaussian_kernel_v5(whd):\n",
    "    # 定义新的维度\n",
    "    new_dims_w = int(whd[0])   # 新的长方体的维度\n",
    "    new_dims_h = int(whd[1])\n",
    "    new_dims_d = int(whd[2])\n",
    "    size_max = int(np.max(whd))\n",
    "\n",
    "\n",
    "    if new_dims_w % 2 == 0:\n",
    "        new_dims_w += 1\n",
    "    if new_dims_h % 2 == 0:\n",
    "        new_dims_h += 1\n",
    "    if new_dims_d % 2 == 0:\n",
    "        new_dims_d += 1\n",
    "    if size_max % 2 == 0:\n",
    "        size_max += 1\n",
    "\n",
    "    new_w = new_dims_w / size_max\n",
    "    new_h = new_dims_h / size_max\n",
    "    new_d = new_dims_d / size_max\n",
    "\n",
    "    gaussian_kernel = create_gaussian_base(size_max, 0.3)\n",
    "    # 使用scipy.ndimage.zoom函数来伸缩高斯核\n",
    "    # rescaled_kernel = zoom(gaussian_kernel, (new_dims_w, new_dims_h, new_dims_d))\n",
    "    rescaled_kernel = zoom(gaussian_kernel, (new_w, new_h, new_d))\n",
    "    rescaleded_kernel = add_dim_inarray(rescaled_kernel)\n",
    "    # print(f'rescaled_kernel.shape is {rescaled_kernel.shape}, and the rescaleded_kernel.shape is {rescaleded_kernel.shape}')\n",
    "\n",
    "    return rescaleded_kernel\n",
    "\n",
    "\n",
    "\n",
    "def add_dim_inarray(array):\n",
    "    shape = np.shape(array)\n",
    "    w, h, d = shape\n",
    "\n",
    "    if w % 2 == 0:\n",
    "        w += 1\n",
    "        new_array = np.ones((w, h, d))\n",
    "        # print((w-1)/2+ 1)\n",
    "        new_array[0:int((w-1)/2 + 1), :, :] = array[0:int((w-1)/2 + 1), :, :]\n",
    "        new_array[int((w-1)/2 + 1), :, :] = array[int((w-1)/2 ), :, :]\n",
    "        new_array[int((w-1)/2 + 2) : w+1 , :, :] = array[int((w-1)/2 + 1) : w, :, :]\n",
    "        array = new_array\n",
    "    if h % 2 == 0:\n",
    "        h += 1\n",
    "        new_array = np.ones((w, h, d))\n",
    "        new_array[:, 0:int((h-1)/2 + 1), :] = array[:, 0:int((h-1)/2 + 1), :]\n",
    "        new_array[:, int((h-1)/2 + 1), :] = array[:, int((h-1)/2 ), :]\n",
    "        new_array[:, int((h-1)/2 + 2) : w+1 , :] = array[:, int((h-1)/2 + 1) : h, :]\n",
    "        array = new_array\n",
    "    if d % 2 == 0:\n",
    "        d += 1\n",
    "        new_array = np.ones((w, h, d))\n",
    "        new_array[:, :, 0:int((d-1)/2 + 1)] = array[:, :, 0:int((d-1)/2 + 1)]\n",
    "        new_array[:, :, int((d-1)/2 + 1)] = array[:, :, int((d-1)/2 )]\n",
    "        new_array[:, :, int((d-1)/2 + 2) : d+1 ] = array[:, :, int((d-1)/2 + 1) : d]\n",
    "        array = new_array\n",
    "\n",
    "    return array\n",
    "\n",
    "\n",
    "\n",
    "def place_gaussian(arr, kernel, pos):\n",
    "    x, y, z = pos\n",
    "    kx, ky, kz = kernel.shape\n",
    "    # 计算高斯核在数组中的位置\n",
    "    x1, x2 = max(0, x-kx//2), min(arr.shape[0], x+kx//2+1)\n",
    "    y1, y2 = max(0, y-ky//2), min(arr.shape[1], y+ky//2+1)\n",
    "    z1, z2 = max(0, z-kz//2), min(arr.shape[2], z+kz//2+1)\n",
    "    # 计算高斯核在自身中的位置\n",
    "    kx1, kx2 = max(0, kx//2-x), min(kx, kx//2-x+arr.shape[0])\n",
    "    ky1, ky2 = max(0, ky//2-y), min(ky, ky//2-y+arr.shape[1])\n",
    "    kz1, kz2 = max(0, kz//2-z), min(kz, kz//2-z+arr.shape[2])\n",
    "    # 将高斯核放置在指定位置\n",
    "    arr[x1:x2,y1:y2,z1:z2] = np.maximum(arr[x1:x2,y1:y2,z1:z2], kernel[kx1:kx2,ky1:ky2,kz1:kz2])\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "# def create_hmap_v5(coordinates, shape):\n",
    "#     arr = np.zeros(shape)\n",
    "#     for coords in coordinates:\n",
    "#         x1, y1, z1, x2, y2, z2 = coords\n",
    "#         whd = [int(x2-x1), int(y2-y1), int(z2-z1)]\n",
    "#         coord = [int((x2+x1)/2), int((y2+y1)/2), int((z2+z1)/2)]\n",
    "#         kernel = create_gaussian_kernel_v5(whd)\n",
    "#         print(kernel.shape)\n",
    "#         arr = place_gaussian(arr, kernel, coord)\n",
    "\n",
    "#     return arr\n",
    "\n",
    "\n",
    "def create_hmap_v5(coordinates, shape):\n",
    "    arr = np.zeros(shape)\n",
    "    for coords in coordinates:\n",
    "        coord = [int(x) for x in coords[0:3]]\n",
    "        whd = [int(x) for x in coords[3:6]]\n",
    "        kernel = create_gaussian_kernel_v5(whd)\n",
    "        arr = place_gaussian(arr, kernel, coord)\n",
    "\n",
    "    return arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [04:49,  2.89s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import binary_dilation\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "#* trans the data to the test\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_label(data_root_path, part, name, number):\n",
    "\n",
    "    img_path = data_root_path.joinpath(part).joinpath(name)\n",
    "    file_name = img_path.iterdir() # 迭代器不能够去进行索引\n",
    "    file_name = list(file_name)\n",
    "    if len(file_name) == 0:\n",
    "        print(f'the part : {part}, the name : {name} , have no data!!!!!!!!')\n",
    "    else:\n",
    "        img = tio.ScalarImage(os.path.join(img_path, file_name[0]))\n",
    "        source = os.path.join(img_path, file_name[0])\n",
    "        destination = f'D:\\\\Work_file\\\\uii_lymph_nodes_data\\\\DATASET\\\\testingTr\\\\lymph_{number}_0000.nii.gz'\n",
    "        shutil.copy(source, destination)\n",
    "        # img.save(f'D:\\\\Work_file\\\\uii_lymph_nodes_data\\\\DATASET\\\\imagesTr\\\\lymph_{number}_0000.nii.gz')\n",
    "        # * 读取csv文件中的世界坐标\n",
    "        worldcoord = pd.read_csv(f'{data_root_path}/lymph_csv_refine/CTA_thin_std_{part}_lymph_refine.csv')\n",
    "        # csv_filename = f'{data_root_path}/lymph_csv_refine/{part}_npyrefine.csv'\n",
    "        csv_filename = f'/public_bme/data/xiongjl/lymph_det/csv_files/{part}_npyrefine.csv'\n",
    "        raw = worldcoord[worldcoord['image_path'].str.contains(name)]\n",
    "        coords = []\n",
    "        for i in range(len(raw)):\n",
    "            x = raw.iloc[i, 2]\n",
    "            y = raw.iloc[i, 3]\n",
    "            z = raw.iloc[i, 4]\n",
    "            width = raw.iloc[i, 5]\n",
    "            height = raw.iloc[i, 6]\n",
    "            depth = raw.iloc[i, 7]\n",
    "            coords.append([x, y, z, width, height, depth]) # 这个是世界坐标系\n",
    "        # print(f'the world coords is {coords}')\n",
    "\n",
    "        # * 把世界坐标系转化为图像坐标系\n",
    "        origin = img.origin\n",
    "        spacing = img.spacing\n",
    "        shape = img.shape[1:]\n",
    "        # print(f'the origin is {origin}')\n",
    "        img_coords = []\n",
    "        for coord in coords:\n",
    "            img_coord = (np.array(coord[0:3]) - np.array(origin) * np.array([-1., -1., 1.]) ) / np.array(spacing) # img.spacing\n",
    "            coord[3: 6] = coord[3: 6] / np.array(spacing)\n",
    "            img_coords.append([img_coord[0], img_coord[1], img_coord[2], coord[3], coord[4], coord[5]])   #! xyzwhd\n",
    "\n",
    "        # * 开始生成并且保存这个hmap\n",
    "        hmap = create_hmap_v5(img_coords, shape)\n",
    "        hmap = np.where(hmap >= 0.5, 1, 0)\n",
    "        hmap_nii = tio.ScalarImage(tensor=torch.tensor(hmap).unsqueeze(0), affine=img.affine)\n",
    "        hmap_nii.save(f'D:\\\\Work_file\\\\uii_lymph_nodes_data\\\\DATASET\\\\test_labelTr\\\\lymph_{number}.nii.gz')\n",
    "\n",
    "    return hmap\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    data_root_path = Path('D:\\\\Work_file\\\\uii_lymph_nodes_data')\n",
    "    parts = ['testing']\n",
    "\n",
    "\n",
    "    for part in parts:\n",
    "        names_list = []\n",
    "        with open(f'D:\\\\Work_file\\\\uii_lymph_nodes_data\\\\lymph_csv_refine\\\\{part}_names.csv') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            for row in reader:\n",
    "                names_list.append(row[0])\n",
    "\n",
    "        # print(names_list)\n",
    "        # print(len(names_list))\n",
    "\n",
    "\n",
    "        for i, name in tqdm(enumerate(names_list)):\n",
    "            number = str(i)\n",
    "            if len(number) == 1:\n",
    "                number = f'00{number}'\n",
    "            elif len(number) == 2:\n",
    "                number = f'0{number}'\n",
    "            elif len(number) == 3:\n",
    "                pass\n",
    "            else:\n",
    "                print(f'the number given wrong, now is {number}')\n",
    "            hmap = generate_label(data_root_path, part, name, number)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "det",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
